<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
 <title>分层模型同时提高阅读理解和情感分类 </title>



<meta name="description" content="伤口是光能照进来的地方">


<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<link rel="stylesheet" id="ct-tracks-google-fonts-css" href="//fonts.googleapis.com/css?family=Raleway%3A400%2C700&amp;subset=latin%2Clatin-ext&amp;ver=4.7.2" type="text/css" media="all">
<link rel="stylesheet" href="https://ne7ermore.github.io/css/font-awesome.min.css" type='text/css' media='all'>

<link href="https://ne7ermore.github.io/css/style.css" rel="stylesheet" id="theme-stylesheet" type='text/css' media='all'>

<link href="https://ne7ermore.github.io/css/custom.css" rel="stylesheet" type='text/css' media='all'>
<link rel="shortcut icon" href="https://ne7ermore.github.io/img/favicon.jpeg" type="image/x-icon">
<link rel="icon" href="https://ne7ermore.github.io/img/favicon.jpeg" type="image/x-icon">


</head>


<body class="post-template-default single single-post single-format-standard ct-body singular singular-post not-front standard">
  
  <div id="overflow-container" class="overflow-container">
    <a class="skip-content" href="#main">Skip to content</a>
    <header id="site-header" class="site-header" role="banner">
      <div class='top-navigation'>
        <div class='container'>

  <div id="menu-secondary" class="menu-container menu-secondary" role="navigation">
    <button id="toggle-secondary-navigation" class="toggle-secondary-navigation"><i class="fa fa-plus"></i></button>

    <div class="menu">

      <ul id="menu-secondary-items" class="menu-secondary-items">
        
        <li id="menu-item" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item">
          <a href="/categories/code">code</a>
        </li>
        
        <li id="menu-item" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item">
          <a href="/categories/deep-learning">deep-learning</a>
        </li>
        
        <li id="menu-item" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item">
          <a href="/categories/reinforce-learning">reinforce-learning</a>
        </li>
        
        <li id="menu-item" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item">
          <a href="/categories/tensorflow">tensorflow</a>
        </li>
        

      </ul>

    </div>

  </div>


  <ul class="social-media-icons">


    

    

    

    

    
    <li>
      <a href="mailto:liaoyuanhuo1987@gmail.com" data-animate-hover="pulse" class="email">
        <i class="fa fa-envelope" title="email"></i>
        <span class="screen-reader-text">email</span>
      </a>
    </li>
    

    

    


    
    <li>
      <a href="https://github.com/ne7ermore" data-animate-hover="pulse" class="github" target="_blank">
        <i class="fa fa-github" title="github"></i>
        <span class="screen-reader-text">github</span>
      </a>
    </li>
    

  </ul></div>

      </div>

      <div class="container">
        <div id="title-info" class="title-info">
  <div id='site-title' class='site-title'>
    
    <a href="/"> Nevermore </a>
    </div>
  </div>
  <button id="toggle-navigation" class="toggle-navigation">
    <i class="fa fa-bars"></i>
  </button>

  <div id="menu-primary-tracks" class="menu-primary-tracks"></div>
  <div id="menu-primary" class="menu-container menu-primary" role="navigation">
    
    <p class="site-description">Why so serious</p>
    

    <div class="menu">
      <ul id="menu-primary-items" class="menu-primary-items">
        
        
        <li id="menu-item" class='menu-item menu-item-type-custom menu-item-object-custom '>
          <a href="https://ne7ermore.github.io/">Home</a>
        </li>
        
        <li id="menu-item" class='menu-item menu-item-type-post_type menu-item-object-page '>
          <a href="https://ne7ermore.github.io/intro/">Intro</a>
        </li>
        
      </ul>
    </div>

  </div>

      </div>
    </header>

    <div id="main" class="main" role="main">

      
  <div id="loop-container" class="loop-container">
    
    <div class="post type-post status-publish format-standard has-post-thumbnail hentry category-design tag-design tag-standard-2 tag-tagalicious tag-travel entry full-without-featured odd excerpt-1">

      <div class='featured-image lazy lazy-bg-image' data-background="https://ne7ermore.github.io/img/hierarchical-sc/1.png">
      </div>
      
        <div class="entry-meta">
          <span class="date">June 14</span>	<span> / </span>

          <span class="author">
            
            <a href="https://ne7ermore.github.io" title="Posts by Nevermore" rel="author">Nevermore</a>
            
          </span>


          
          <span class="category">
            <span> / </span>

            <a href="/categories/deep-learning">deep-learning</a>
          </span>
          


        </div>
        <div class='entry-header'>
          <h1 class='entry-title'> 分层模型同时提高阅读理解和情感分类</h1>
        </div>
        <div class="entry-container">
          <div class="entry-content">
            <article>
              <p>介绍一篇阅读理解和情感分类耦合的论文</p>
<p>论文地址: <a href="https://arxiv.org/pdf/1805.01089.pdf">戳我</a></p>
<p>训练使用Amazon SNAP Review Dataset(SNAP)</p>
<p>下载过程可以参考<a href="https://github.com/ne7ermore/torch_light/tree/master/hierarchical-sc">repo</a></p>
<!-- raw HTML omitted -->
<p>模型不是很复杂，主要建立在seq2seq基础上，巧妙的将阅读理解和分类结合起来，共同优化，不过文中有些细节并没有交代太清楚，我也只能靠猜测，所以我的结果没有论文效果好</p>
<ul>
<li>第一层：经过embedding，喂入双向lstm，获取最后一个时间序列的hidden和整个时间序列的hidden，然后将正向和逆向的特征加起来</li>
<li>第二层：最后一个时间序列作为decode的初始化hidden，这是传统做法就不详细解释，重点来了，decode时按时间维度，一步一步对下一个word做出预测，并将当前hidden做attention，相同结构不同权重的得出阅读理解和情绪分类的特征，并保存起来，直到时间序列结束</li>
<li>第三层：将第二层保存的时间序列的情绪分类特征和第一层encode整个时间序列的hidden按时间维度拼接起来，过一全连接层得出概率</li>
</ul>
<blockquote>
<p>疑问：
1、论文提到了highway，我不太理解文中所述highway仅仅是第三层中加上了encode的输出呢，还是一篇论文中的highway
2、最后在全连接层之前，降维细节没有说明，我使用简单粗暴的flatten</p>
</blockquote>
<p>给其中一位作者发了邮件，可能太忙没回，如果论文作者看见并有时间可以解释下，非常感谢：)</p>
<blockquote>
<p>代码</p>
</blockquote>
<p><a href="https://github.com/ne7ermore/torch_light/tree/master/hierarchical-sc/">Pytorch版</a></p>
<p><a href="https://github.com/ne7ermore/deeping-flow/tree/master/hierarchical-sc/">Tensorflow版</a></p>
<p>数据预处理就不多说了，具体可以参见项目的readme</p>
<p>以下是pytorch代码，tensorflow请移步github</p>
<p>模型视图</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Model</span>(nn<span style="color:#f92672">.</span>Module):
    <span style="color:#66d9ef">def</span> __init__(self, args, use_cuda):

        super()<span style="color:#f92672">.</span>__init__()

        <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> args<span style="color:#f92672">.</span>__dict__<span style="color:#f92672">.</span>items():
            self<span style="color:#f92672">.</span>__setattr__(k, v)

        self<span style="color:#f92672">.</span>torch <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cuda <span style="color:#66d9ef">if</span> use_cuda <span style="color:#66d9ef">else</span> torch

        self<span style="color:#f92672">.</span>emb <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Embedding(self<span style="color:#f92672">.</span>dict_size, self<span style="color:#f92672">.</span>emb_dim)
        self<span style="color:#f92672">.</span>encode <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>LSTM(input_size<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>emb_dim,
                                    hidden_size<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>rnn_hsz,
                                    num_layers<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
                                    bidirectional<span style="color:#f92672">=</span>True)
        self<span style="color:#f92672">.</span>decode <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>LSTM(input_size<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>rnn_hsz,
                                    hidden_size<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>rnn_hsz,
                                    num_layers<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
        self<span style="color:#f92672">.</span>summ_att_w <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(self<span style="color:#f92672">.</span>rnn_hsz,
                                    self<span style="color:#f92672">.</span>rnn_hsz,
                                    bias<span style="color:#f92672">=</span>False)
        self<span style="color:#f92672">.</span>cls_att_w <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(self<span style="color:#f92672">.</span>rnn_hsz,
                                   self<span style="color:#f92672">.</span>rnn_hsz,
                                   bias<span style="color:#f92672">=</span>False)
        self<span style="color:#f92672">.</span>summ_gen <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(self<span style="color:#f92672">.</span>rnn_hsz, self<span style="color:#f92672">.</span>dict_size)
        self<span style="color:#f92672">.</span>cls_pred <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(
            (self<span style="color:#f92672">.</span>max_ori_len <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>max_sum_len) <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>rnn_hsz, self<span style="color:#f92672">.</span>label_size)

        self<span style="color:#f92672">.</span>dropout <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Dropout(self<span style="color:#f92672">.</span>dropout)

        self<span style="color:#f92672">.</span>_reset_parameters()

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_reset_parameters</span>(self):
        stdv <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.</span> <span style="color:#f92672">/</span> math<span style="color:#f92672">.</span>sqrt(self<span style="color:#f92672">.</span>emb_dim)

        self<span style="color:#f92672">.</span>emb<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>uniform_(<span style="color:#f92672">-</span>stdv, stdv)

        self<span style="color:#f92672">.</span>summ_att_w<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>uniform_(<span style="color:#f92672">-</span>stdv, stdv)

        self<span style="color:#f92672">.</span>cls_att_w<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>uniform_(<span style="color:#f92672">-</span>stdv, stdv)

        self<span style="color:#f92672">.</span>summ_gen<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>uniform_(<span style="color:#f92672">-</span>stdv, stdv)
        self<span style="color:#f92672">.</span>summ_gen<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">0</span>)

        self<span style="color:#f92672">.</span>cls_pred<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>uniform_(<span style="color:#f92672">-</span>stdv, stdv)
        self<span style="color:#f92672">.</span>cls_pred<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">0</span>)

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, original):
        bsz <span style="color:#f92672">=</span> original<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)

        ori_emb <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>emb(original)
        ori_emb_t <span style="color:#f92672">=</span> ori_emb<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)

        encodes, (h, _) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encode(ori_emb_t)
        ori_memory <span style="color:#f92672">=</span> encodes[:, :, :self<span style="color:#f92672">.</span>rnn_hsz] <span style="color:#f92672">+</span> \
            encodes[:, :, self<span style="color:#f92672">.</span>rnn_hsz:]

        ori_hidden <span style="color:#f92672">=</span> (h[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">+</span> h[<span style="color:#ae81ff">1</span>])<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">0</span>)
        c <span style="color:#f92672">=</span> Variable(next(self<span style="color:#f92672">.</span>parameters())<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>new(
            <span style="color:#ae81ff">1</span>, bsz, self<span style="color:#f92672">.</span>rnn_hsz)<span style="color:#f92672">.</span>zero_())

        ori_memory <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dropout(ori_memory)
        ori_hidden <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dropout(ori_hidden)

        dec_hidden <span style="color:#f92672">=</span> (ori_hidden, c)

        word <span style="color:#f92672">=</span> Variable(self<span style="color:#f92672">.</span>torch<span style="color:#f92672">.</span>LongTensor([[BOS]] <span style="color:#f92672">*</span> bsz))
        v_ts, summ_props <span style="color:#f92672">=</span> [], []
        <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(self<span style="color:#f92672">.</span>max_sum_len):
            summ_emb <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>emb(word)<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)
            _, dec_hidden <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>decode(summ_emb, dec_hidden)
            h_state <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dropout(dec_hidden[<span style="color:#ae81ff">0</span>])

            v_c <span style="color:#f92672">=</span> multi_view_att(ori_memory,
                                 self<span style="color:#f92672">.</span>summ_att_w,
                                 h_state, bsz,
                                 self<span style="color:#f92672">.</span>max_ori_len,
                                 self<span style="color:#f92672">.</span>rnn_hsz)
            v_t <span style="color:#f92672">=</span> multi_view_att(ori_memory,
                                 self<span style="color:#f92672">.</span>cls_att_w,
                                 h_state, bsz,
                                 self<span style="color:#f92672">.</span>max_ori_len,
                                 self<span style="color:#f92672">.</span>rnn_hsz)

            props <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>log_softmax(self<span style="color:#f92672">.</span>summ_gen(v_c), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
            _, word <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(props, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span>True)

            v_ts<span style="color:#f92672">.</span>append(v_t<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>))
            summ_props<span style="color:#f92672">.</span>append(props<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>))

        summ_props <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat(summ_props, <span style="color:#ae81ff">1</span>)
        v_ts <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dropout(torch<span style="color:#f92672">.</span>cat(v_ts, <span style="color:#ae81ff">1</span>))
        r <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([v_ts, ori_memory<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)], <span style="color:#ae81ff">1</span>)
        l_props <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>cls_pred(r<span style="color:#f92672">.</span>view(bsz, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>))

        <span style="color:#66d9ef">return</span> summ_props, l_props
</code></pre></div><p>attention代码</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">multi_view_att</span>(ori_memory, att_w, dec_hidden, <span style="color:#f92672">*</span>args):
    bsz, max_len, rnn_hsz <span style="color:#f92672">=</span> args

    dec_hidden <span style="color:#f92672">=</span> att_w(dec_hidden<span style="color:#f92672">.</span>squeeze())
    ori_memory_t <span style="color:#f92672">=</span> ori_memory<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>)

    beta_is <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>exp(torch<span style="color:#f92672">.</span>tanh(torch<span style="color:#f92672">.</span>matmul(dec_hidden, ori_memory_t)))
    beta_i_sum <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sum(beta_is, <span style="color:#ae81ff">0</span>, keepdim<span style="color:#f92672">=</span>True)
    beta_is <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>div(beta_is, beta_i_sum)

    <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">.</span>sum(torch<span style="color:#f92672">.</span>matmul(beta_is, ori_memory), dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</code></pre></div><p>阅读理解算loss时，需要去除pad，所以交叉熵的api CrossEntropyLoss就不实用</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">NlpCrossEntropy</span>(nn<span style="color:#f92672">.</span>Module):
    <span style="color:#66d9ef">def</span> __init__(self):
        super()<span style="color:#f92672">.</span>__init__()

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, props, tgt):
        tgt_props <span style="color:#f92672">=</span> props<span style="color:#f92672">.</span>gather(<span style="color:#ae81ff">2</span>, tgt<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">2</span>))<span style="color:#f92672">.</span>squeeze()
        mask <span style="color:#f92672">=</span> (tgt <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>float()
        <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span>(tgt_props <span style="color:#f92672">*</span> mask)<span style="color:#f92672">.</span>sum() <span style="color:#f92672">/</span> mask<span style="color:#f92672">.</span>sum()
</code></pre></div><p>优化函数需要定制</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ScheduledOptim</span>(object):
    <span style="color:#66d9ef">def</span> __init__(self, optimizer, parameters, lr, clip):
        self<span style="color:#f92672">.</span>optimizer <span style="color:#f92672">=</span> optimizer
        self<span style="color:#f92672">.</span>parameters <span style="color:#f92672">=</span> parameters
        self<span style="color:#f92672">.</span>n_current_epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
        self<span style="color:#f92672">.</span>lr <span style="color:#f92672">=</span> lr
        self<span style="color:#f92672">.</span>clip <span style="color:#f92672">=</span> clip

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">step</span>(self):
        self<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>step()

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">zero_grad</span>(self):
        self<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>zero_grad()

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clip_grad_norm</span>(self):
        torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>clip_grad_norm_(self<span style="color:#f92672">.</span>parameters, self<span style="color:#f92672">.</span>clip)

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">update_learning_rate</span>(self):
        self<span style="color:#f92672">.</span>n_current_epochs <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>

        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>n_current_epochs <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">4</span>:
            self<span style="color:#f92672">.</span>lr <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>lr <span style="color:#f92672">/</span> <span style="color:#ae81ff">2</span>
            <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;| learning rate updated - {}&#34;</span><span style="color:#f92672">.</span>format(self<span style="color:#f92672">.</span>lr))
            <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;-&#39;</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">90</span>)
            <span style="color:#66d9ef">for</span> param_group <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>param_groups:
                param_group[<span style="color:#e6db74">&#39;lr&#39;</span>] <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>lr
</code></pre></div>
            </article>
          </div>
          
      <div class='entry-meta-bottom'>
        

  <div class="entry-categories"><p><span>Categories</span>
    
    <a href="/categories/code" title="View all posts in code">code</a>
    <a href="/categories/deep-learning" title="View all posts in deep-learning">deep-learning</a>
    <a href="/categories/reinforce-learning" title="View all posts in reinforce-learning">reinforce-learning</a>
    <a href="/categories/tensorflow" title="View all posts in tensorflow">tensorflow</a>
  </p>
</div>



<div class="entry-tags"><p><span>Tags</span>
  
  <a href="/tags/cpp" title="View all posts tagged cpp">cpp</a>
  
  <a href="/tags/golang" title="View all posts tagged golang">golang</a>
  
  <a href="/tags/python" title="View all posts tagged python">python</a>
  
  <a href="/tags/%E7%AE%97%E6%B3%95" title="View all posts tagged 算法">算法</a>
  

</p></div>	</div>

<div class="author-meta">

  <div class="author">
    <img alt='Nevermore' src="https://www.gravatar.com/avatar/441d6f3623599f66569ae8478cf21f68?s=100&d=identicon" class='avatar avatar-72 photo' height='72' width='72'>

    <span>
      Written by:<a href="https://ne7ermore.github.io" title="Posts by Nevermore" rel="author">Nevermore</a>        </span>
    </div>
    <div class="bio">
      
      <p>步步生姿，空锁满庭花雨。胜将娇花比。</p>
      


      

    


  



<a class="email" target="_blank"
href="mailto:liaoyuanhuo1987@gmail.com">
<i class="fa fa-envelope"
title="email icon"></i>
</a>







<a class="github" target="_blank"
href="https://github.com/ne7ermore">
<i class="fa fa-github"
title="github icon"></i>
</a>


</div>
</div>

</div>
</div>

<section id="comments" class="comments">
  

  




</section>
</div>

 



    </div>

    <footer id="site-footer" class="site-footer" role="contentinfo">
	<h1>
    
    <a href=""> Nevermore </a>
    
	</h1>

			
			<p class="site-description">Why so serious</p>
			

		<div id="menu-footer" class="menu-container menu-footer" role="navigation">
		<div class="menu">

      <ul id="menu-footer-items" class="menu-footer-items">
        
</ul>

</div>	</div>

<ul class="social-media-icons">

        

        


        

        

        
        <li>
        <a href="mailto:liaoyuanhuo1987@gmail.com"  class="email">
            <i class="fa fa-envelope" title="email"></i>
            <span class="screen-reader-text">email</span>
        </a>
        </li>
        

        

        


        
        <li>
        <a href="https://github.com/ne7ermore"  class="github" target="_blank">
            <i class="fa fa-github" title="github"></i>
            <span class="screen-reader-text">github</span>
        </a>
        </li>
        
				</ul>	<div class="design-credit">
		
		<p>© Nevermore | 2019</p>
		
    </div>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\[','\]']],
            processEscapes: true,
            processEnvironments: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            TeX: { equationNumbers: { autoNumber: "AMS" },
                extensions: ["AMSmath.js", "AMSsymbols.js"] }
            }
        });
    </script>
</footer>

  </div>
  <script src="https://ne7ermore.github.io/js/jquery.min.js"></script>
<script src="https://ne7ermore.github.io/js/jquerymigrate.js"></script>
<script src="https://ne7ermore.github.io/js/production.min.js"></script>

</body>
</html>
